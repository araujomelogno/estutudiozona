{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de Transformación de Datos de Encuesta\n",
    "\n",
    "Este notebook implementa un pipeline para procesar y transformar datos de una encuesta desde un formato ancho (como se exporta típicamente de SPSS) a un formato largo, adecuado para análisis y visualización en herramientas como Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos y Limpieza Inicial\n",
    "\n",
    "El primer paso es cargar los datos de la encuesta desde un archivo `.sav` (SPSS). Utilizamos `pyreadstat` para leer el archivo, ya que nos permite acceder tanto a los datos como a los metadatos (etiquetas de variables y valores).\n",
    "\n",
    "Realizamos dos acciones iniciales:\n",
    "1.  Extraemos los metadatos (`dict_value_labels`, `dict_column_labels`) para usarlos más adelante.\n",
    "2.  Estandarizamos los nombres de las columnas a minúsculas para facilitar el manejo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "e4BHNdp9tq6i"
   },
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Carga el archivo .sav y sus metadatos.\n",
    "# NOTA: La ruta es local y debe ser ajustada si se ejecuta en otro entorno.\n",
    "df, meta = pyreadstat.read_sav(\n",
    "        \"/Users/blanc/Library/CloudStorage/GoogleDrive-dblancbellido@gmail.com/.shortcut-targets-by-id/153DRxBD4jspE3sko8JH1R6j2AYv7OrgD/PBI - Comunidad Zona/datos/BASE_PBI.sav\",\n",
    "        apply_value_formats=True,\n",
    "        formats_as_category=True,\n",
    "        formats_as_ordered_category=False\n",
    ")\n",
    "\n",
    "# Almacena los metadatos en diccionarios para su uso posterior.\n",
    "dict_value_labels = meta.variable_value_labels\n",
    "dict_column_labels = meta.column_names_to_labels\n",
    "\n",
    "# Convierte todos los nombres de columna a minúsculas para consistencia.\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clasificación de Variables\n",
    "\n",
    "Las variables de la encuesta se clasifican en tres grupos para su procesamiento diferenciado:\n",
    "\n",
    "- **`segmentadores`**: Variables demográficas o de corte que se usarán para segmentar los datos (ej. `sexo`, `edad_tramo`).\n",
    "- **`simples`**: Preguntas de respuesta única (ej. una escala de satisfacción).\n",
    "- **`compuestas`**: Preguntas de respuesta múltiple, donde cada opción se representa como una columna separada en el formato original (ej. `transporte1a`, `transporte1b`).\n",
    "\n",
    "Primero, definimos manualmente la lista de `segmentadores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "s1QHBMvYtq6n"
   },
   "outputs": [],
   "source": [
    "segmentadores = [\n",
    "    'idbase',\n",
    "    'sexo',\n",
    "    'edad_tramo',\n",
    "    'edad',\n",
    "    'depto',\n",
    "    'barrio',\n",
    "    'hijos',\n",
    "    'cargo_declarado',\n",
    "    'industria_rec',\n",
    "    'modalidad_trabajo',\n",
    "    'edificios1',\n",
    "    'cliente_rec',\n",
    "    'barrio2_monte',\n",
    "    'canelones',\n",
    "    'canelones_localidades',\n",
    "    'canelones_otr',\n",
    "    'privado_cod',\n",
    "    'identificador',\n",
    "    'idequipos',\n",
    "    'edad_rec',\n",
    "    'edu_rec',\n",
    "    'ponderador'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, clasificamos el resto de las columnas como `simples` o `compuestas` de forma programática. La lógica se basa en la nomenclatura de las columnas:\n",
    "\n",
    "- Si el nombre de la columna contiene un número seguido de una letra (ej. `hijos10a`), se considera `compuesta`.\n",
    "- De lo contrario, se considera `simple`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NZzNLAPXtq6n"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Función para analizar el nombre de una columna y separarlo en base, número y letra.\n",
    "def separar_elemento(elemento):\n",
    "    match = re.search(r'\\d', elemento)\n",
    "    if match:\n",
    "        pos = match.start()\n",
    "        parte1 = elemento[:pos]\n",
    "        parte2 = elemento[pos]\n",
    "        parte3 = elemento[pos+1:] if pos+1 < len(elemento) else ''\n",
    "        return parte1, parte2, parte3\n",
    "    else:\n",
    "        return elemento, '', ''\n",
    "\n",
    "# Aplica la función a todas las columnas.\n",
    "resultado = [separar_elemento(e) for e in df.columns]\n",
    "\n",
    "# Inicializa las listas, incluyendo 'idbase' y 'ponderador' que son claves para el análisis.\n",
    "simples = ['idbase', 'ponderador']\n",
    "compuestas = ['idbase', 'ponderador']\n",
    "\n",
    "# Itera sobre los nombres de columna para clasificarlos.\n",
    "for res in resultado:\n",
    "    variable = ''.join(res)\n",
    "    if variable not in segmentadores:\n",
    "        # Si la parte 3 no está vacía, es una variable compuesta (ej. 'hijos1a').\n",
    "        if res[2] != '':\n",
    "            compuestas.append(variable)\n",
    "        else:\n",
    "            simples.append(variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación de DataFrames por Tipo de Variable\n",
    "\n",
    "Con las variables ya clasificadas, creamos tres DataFrames separados, cada uno conteniendo solo las columnas de su respectivo tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Rs8kuOYmtq6o"
   },
   "outputs": [],
   "source": [
    "df_segmentadores = df[segmentadores]\n",
    "df_simples = df[simples]\n",
    "df_compuestas = df[compuestas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformación de Formato Ancho a Largo (Pivot)\n",
    "\n",
    "Ahora, transformamos los DataFrames de variables `simples` y `compuestas` para que tengan un formato largo. Esto se hace con la función `melt` de pandas, que convierte las columnas en filas.\n",
    "\n",
    "El resultado es un DataFrame con las columnas:\n",
    "- `idbase`: El identificador del encuestado.\n",
    "- `ponderador`: El peso de la encuesta.\n",
    "- `variable`: El nombre de la pregunta (el nombre de la columna original).\n",
    "- `value`: La respuesta dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Cu5SCvhXtq6p"
   },
   "outputs": [],
   "source": [
    "# Pivotea el DataFrame de variables compuestas.\n",
    "df_compuestas_pivoted = df_compuestas.melt(\n",
    "    id_vars = ['idbase', 'ponderador'],\n",
    ")\n",
    "df_compuestas_pivoted.dropna(inplace=True)\n",
    "df_compuestas_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_VmfHqDttq6p"
   },
   "outputs": [],
   "source": [
    "# Pivotea el DataFrame de variables simples.\n",
    "df_simples_pivoted = df_simples.melt(\n",
    "    id_vars = ['idbase', 'ponderador']\n",
    ")\n",
    "df_simples_pivoted.dropna(inplace=True)\n",
    "df_simples_pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Carga y Procesamiento del Diccionario de Datos\n",
    "\n",
    "Cargamos un archivo de Excel (`Indice.xlsx`) que funciona como un diccionario de datos. Contiene información adicional sobre cada variable, como el texto completo de la pregunta. \n",
    "\n",
    "En este paso, también procesamos la columna `Pregunta` para separar el tema principal de la pregunta específica, creando las columnas `opciones` y `preguntas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AjGSONVttq6p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Carga el archivo Excel que contiene el diccionario de datos.\n",
    "# NOTA: La ruta es local y debe ser ajustada.\n",
    "indice = pd.read_excel('/Users/blanc/Library/CloudStorage/GoogleDrive-dblancbellido@gmail.com/.shortcut-targets-by-id/153DRxBD4jspE3sko8JH1R6j2AYv7OrgD/PBI - Comunidad Zona/datos/Indice.xlsx')\n",
    "# Estandariza la columna 'Indicador' a minúsculas para que coincida con los nombres de las variables.\n",
    "indice['Indicador'] = indice['Indicador'].str.lower()\n",
    "# Filtra filas no deseadas.\n",
    "indice_filtrado = indice[indice['Pregunta'] != 0].copy()\n",
    "indice_filtrado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NnfYgujrtq6q"
   },
   "outputs": [],
   "source": [
    "# Función para separar el texto de la pregunta en 'opción' y 'pregunta' usando ':' como delimitador.\n",
    "def pregunta_y_opcion(row):\n",
    "    pregunta_partida = row.split(':')\n",
    "    try:\n",
    "        opcion = pregunta_partida[0]\n",
    "        pregunta = pregunta_partida[1]\n",
    "    except:\n",
    "        opcion = 'No option'\n",
    "        pregunta = pregunta_partida[0]\n",
    "    return opcion, pregunta\n",
    "\n",
    "# Limpia dobles dos puntos para evitar errores en la separación.\n",
    "indice_filtrado['Pregunta'] = indice_filtrado['Pregunta'].str.replace('::', ':')\n",
    "\n",
    "# Aplica la función para crear las nuevas columnas.\n",
    "results = indice_filtrado['Pregunta'].apply(pregunta_y_opcion)\n",
    "\n",
    "opciones = []\n",
    "preguntas = []\n",
    "for row in results:\n",
    "    opciones.append(row[0])\n",
    "    preguntas.append(row[1])\n",
    "\n",
    "indice_filtrado['opciones'] = opciones\n",
    "indice_filtrado['preguntas'] = preguntas\n",
    "\n",
    "indice_filtrado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Enriquecimiento de Datos\n",
    "\n",
    "Unimos los DataFrames transformados (`simples` y `compuestas`) con el diccionario de datos (`indice_filtrado`). Esto añade el texto de la pregunta y la opción a cada fila, enriqueciendo los datos para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "06p8dnUGtq6q"
   },
   "outputs": [],
   "source": [
    "# Une el DataFrame de compuestas con el índice.\n",
    "df_compuestas_joined = df_compuestas_pivoted.merge(\n",
    "    indice_filtrado[['Indicador', 'preguntas', 'opciones']],\n",
    "    how = 'inner',\n",
    "    left_on = 'variable',\n",
    "    right_on = 'Indicador'\n",
    ")\n",
    "df_compuestas_joined.drop(['Indicador'], axis = 1, inplace=True)\n",
    "\n",
    "df_compuestas_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VTw3QtDWtq6q"
   },
   "outputs": [],
   "source": [
    "# Une el DataFrame de simples con el índice.\n",
    "df_simples_joined = df_simples_pivoted.merge(\n",
    "    indice_filtrado[['Indicador', 'preguntas', 'opciones']],\n",
    "    how = 'inner',\n",
    "    left_on = 'variable',\n",
    "    right_on = 'Indicador'\n",
    ")\n",
    "df_simples_joined.drop(['Indicador'], axis = 1, inplace=True)\n",
    "df_simples_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Unión y Limpieza Final\n",
    "\n",
    "Combinamos los DataFrames `simples` y `compuestos` ya enriquecidos en un único DataFrame final. Luego, realizamos una limpieza clave: eliminamos las filas con el valor `Unchecked`, que son comunes en preguntas de opción múltiple y no aportan valor al análisis.\n",
    "\n",
    "Finalmente, exportamos el DataFrame limpio a un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "gM59amNwtq6q"
   },
   "outputs": [],
   "source": [
    "df_simples_joined.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rdLz94jdtq6r"
   },
   "outputs": [],
   "source": [
    "# Concatena los dos DataFrames.\n",
    "df_union = pd.concat([df_compuestas_joined, df_simples_joined], axis = 0, ignore_index=True)\n",
    "df_union.drop_duplicates(inplace=True)\n",
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "0T_iSx13tq6r"
   },
   "outputs": [],
   "source": [
    "# Filtra las filas que no son 'Unchecked'.\n",
    "df_pivoted_without_unchecked = df_union[df_union.value != 'Unchecked']\n",
    "# Exporta el resultado a un archivo CSV.\n",
    "df_pivoted_without_unchecked.to_csv('df_pivoted_without_unchecked.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Procesamiento Adicional de Segmentadores\n",
    "\n",
    "Los datos de segmentación también se procesan y exportan por separado. Esto incluye:\n",
    "1.  Crear una columna `Sin filtro` para permitir análisis no segmentados.\n",
    "2.  Agrupar los departamentos en categorías más amplias (`Montevideo`, `Canelones`, `Resto`).\n",
    "3.  Pivotar el DataFrame de segmentadores a un formato largo.\n",
    "4.  Asignar índices numéricos a los valores para su uso en modelos de datos.\n",
    "5.  Exportar los resultados a archivos CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "c7gb4K3Itq6s"
   },
   "outputs": [],
   "source": [
    "df_segmentadores['Sin filtro'] = 'Sin filtro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_segmentadores['depto'] = df_segmentadores.apply(lambda x: x['depto'] if x['depto'] in ['Montevideo', 'Canelones'] else 'Resto', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "6ZELq1sutq6s"
   },
   "outputs": [],
   "source": [
    "df_segmentadores_pivoted = df_segmentadores.melt(\n",
    "    id_vars = ['idbase', 'ponderador'],\n",
    ")\n",
    "df_segmentadores_pivoted.dropna(inplace=True)\n",
    "df_segmentadores_pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet =  {k.lower(): v for k, v in dict_value_labels.items()}\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "GMj757_ltq6s"
   },
   "outputs": [],
   "source": [
    "def insert_raw_values(row):\n",
    "    variable = row['variable']\n",
    "    value = row['value']\n",
    "    try:\n",
    "        raw_dict = alphabet[variable]\n",
    "        raw_value = list(raw_dict.keys())[list(raw_dict.values()).index(value)]\n",
    "        raw_value_int = int(raw_value)\n",
    "    except:\n",
    "        raw_value_int = 0\n",
    "    return raw_value_int\n",
    "\n",
    "unique_segmentadores = df_segmentadores_pivoted[['variable','value']].drop_duplicates()\n",
    "\n",
    "unique_segmentadores['raw_value']= unique_segmentadores.apply(insert_raw_values, axis= 1)\n",
    "\n",
    "unique_segmentadores_with_index = unique_segmentadores.sort_values(['variable', 'raw_value']).reset_index(drop=True).reset_index()\n",
    "\n",
    "df_segmentadores_pivoted = df_segmentadores_pivoted.merge(\n",
    "    unique_segmentadores_with_index,\n",
    "    left_on = ['variable', 'value'],\n",
    "    right_on = ['variable', 'value']\n",
    ")\n",
    "\n",
    "df_segmentadores_pivoted.to_csv('df_segmentadores_pivoted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una copia para no modificar el DataFrame original.\n",
    "df_segmentadores_addition = df_segmentadores_pivoted.copy()\n",
    "\n",
    "# Crea una fila 'Total' para cada grupo de segmentación.\n",
    "df_segmentadores_addition['value'] = 'Total'\n",
    "df_segmentadores_addition['index'] = 0\n",
    "\n",
    "# Concatena el DataFrame original con el de totales.\n",
    "df_segmentadores_with_totals = pd.concat([df_segmentadores_pivoted, df_segmentadores_addition], axis = 0, ignore_index=True)\n",
    "\n",
    "# Excluye la categoría 'Sin filtro' que ya cumplió su propósito.\n",
    "df_segmentadores_with_totals = df_segmentadores_with_totals.copy()[df_segmentadores_with_totals['value'] != 'Sin filtro']\n",
    "\n",
    "# Exporta el resultado final a CSV.\n",
    "df_segmentadores_with_totals.to_csv('df_segmentadores_with_totals.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}